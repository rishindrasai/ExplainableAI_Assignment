{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfLnDKajANUbnmwxDXAH9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishindrasai/ExplainableAI_Assignment/blob/main/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "g2taQCh2uk1r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrHpKg_2ujXo",
        "outputId": "3a9a96ff-4fbd-4e89-ea16-abbdd95bc142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression equation: y_hat = a + b * x\n",
            "a (intercept) = 87.857142857\n",
            "b (slope)     = 37.857142857\n",
            "\n",
            "Baseline (mean of y): 156.0\n",
            "\n",
            "Prediction table:\n",
            " x (challenges)  actual y (users)  predicted y  baseline (mean y)  SHAP value (y_hat - baseline)  residual (actual - pred)\n",
            "              1               120      125.714              156.0                        -30.286                    -5.714\n",
            "              2               160      163.571              156.0                          7.571                    -3.571\n",
            "              3               200      201.429              156.0                         45.429                    -1.429\n",
            "              1               130      125.714              156.0                        -30.286                     4.286\n",
            "              2               170      163.571              156.0                          7.571                     6.429\n",
            "\n",
            "Model performance metrics\n",
            "R-squared: 0.973994\n",
            "RMSE:      4.629100\n",
            "\n",
            "Per-row interpretations:\n",
            "Row 1: x=1 -> predicted 125.714. SHAP=-30.286 (decreases relative to baseline). Model overpredicted (actual < predicted).\n",
            "Row 2: x=2 -> predicted 163.571. SHAP=7.571 (increases relative to baseline). Model overpredicted (actual < predicted).\n",
            "Row 3: x=3 -> predicted 201.429. SHAP=45.429 (increases relative to baseline). Model overpredicted (actual < predicted).\n",
            "Row 4: x=1 -> predicted 125.714. SHAP=-30.286 (decreases relative to baseline). Model underpredicted (actual > predicted).\n",
            "Row 5: x=2 -> predicted 163.571. SHAP=7.571 (increases relative to baseline). Model underpredicted (actual > predicted).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# data\n",
        "x = np.array([1, 2, 3, 1, 2], dtype=float)\n",
        "y = np.array([120, 160, 200, 130, 170], dtype=float)\n",
        "\n",
        "# fit linear regression y = a + b*x using ordinary least squares\n",
        "X = np.vstack([np.ones_like(x), x]).T\n",
        "coef, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n",
        "a = float(coef[0])\n",
        "b = float(coef[1])\n",
        "\n",
        "# predictions\n",
        "y_hat = a + b * x\n",
        "\n",
        "# baseline (mean of actual y)\n",
        "baseline = float(y.mean())\n",
        "\n",
        "# SHAP value per instruction (y_hat - baseline) assigned to feature x\n",
        "shap_values = y_hat - baseline\n",
        "\n",
        "# residuals and metrics\n",
        "residuals = y - y_hat\n",
        "r2 = float(r2_score(y, y_hat))\n",
        "rmse = float(np.sqrt(mean_squared_error(y, y_hat)))\n",
        "\n",
        "# prepare dataframe for the prediction table\n",
        "df = pd.DataFrame({\n",
        "    \"x (challenges)\": x.astype(int),\n",
        "    \"actual y (users)\": y.astype(int),\n",
        "    \"predicted y\": np.round(y_hat, 3),\n",
        "    \"baseline (mean y)\": np.round(baseline, 3),\n",
        "    \"SHAP value (y_hat - baseline)\": np.round(shap_values, 3),\n",
        "    \"residual (actual - pred)\": np.round(residuals, 3),\n",
        "})\n",
        "\n",
        "print(\"Regression equation: y_hat = a + b * x\")\n",
        "print(f\"a (intercept) = {a:.9f}\")\n",
        "print(f\"b (slope)     = {b:.9f}\")\n",
        "print()\n",
        "print(\"Baseline (mean of y):\", baseline)\n",
        "print()\n",
        "print(\"Prediction table:\")\n",
        "print(df.to_string(index=False))\n",
        "print()\n",
        "print(\"Model performance metrics\")\n",
        "print(f\"R-squared: {r2:.6f}\")\n",
        "print(f\"RMSE:      {rmse:.6f}\")\n",
        "print()\n",
        "# Per-row interpretation lines\n",
        "print(\"Per-row interpretations:\")\n",
        "for i, row in df.iterrows():\n",
        "    xi = int(row[\"x (challenges)\"])\n",
        "    actual = int(row[\"actual y (users)\"])\n",
        "    pred = float(row[\"predicted y\"])\n",
        "    shapv = float(row[\"SHAP value (y_hat - baseline)\"])\n",
        "    resid = float(row[\"residual (actual - pred)\"])\n",
        "    if resid > 0:\n",
        "        pred_vs_actual = \"Model underpredicted (actual > predicted).\"\n",
        "    elif resid < 0:\n",
        "        pred_vs_actual = \"Model overpredicted (actual < predicted).\"\n",
        "    else:\n",
        "        pred_vs_actual = \"Exact prediction.\"\n",
        "    direction = \"increases\" if shapv > 0 else (\"decreases\" if shapv < 0 else \"no effect\")\n",
        "    print(f\"Row {i+1}: x={xi} -> predicted {pred:.3f}. SHAP={shapv:.3f} ({direction} relative to baseline). {pred_vs_actual}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "HCE62-CPu8Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Dataset\n",
        "data = pd.DataFrame({\n",
        "    \"Emails\": [100, 80, 120, 90, 70],\n",
        "    \"TopicScore\": [8, 6, 9, 5, 4],\n",
        "    \"Attendance\": [200, 160, 230, 150, 130]\n",
        "})\n",
        "\n",
        "X = data[[\"Emails\", \"TopicScore\"]]\n",
        "y = data[\"Attendance\"]\n",
        "\n",
        "# Train regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coef_emails, coef_topic = model.coef_\n",
        "\n",
        "# Regression equation\n",
        "print(f\"Regression Equation: y = {intercept:.2f} + {coef_emails:.2f}*Emails + {coef_topic:.2f}*TopicScore\")\n",
        "\n",
        "# Baseline value (mean attendance)\n",
        "baseline = y.mean()\n",
        "print(f\"Baseline (mean attendance): {baseline:.2f}\")\n",
        "\n",
        "# Predictions\n",
        "data[\"Predicted\"] = model.predict(X)\n",
        "\n",
        "# SHAP decomposition\n",
        "data[\"SHAP_Emails\"] = coef_emails * (data[\"Emails\"] - X[\"Emails\"].mean())\n",
        "data[\"SHAP_Topic\"] = coef_topic * (data[\"TopicScore\"] - X[\"TopicScore\"].mean())\n",
        "\n",
        "# Validate: Predicted = Baseline + SHAP_Emails + SHAP_Topic\n",
        "data[\"SHAP_Sum\"] = baseline + data[\"SHAP_Emails\"] + data[\"SHAP_Topic\"]\n",
        "\n",
        "# Compare actual vs predicted\n",
        "print(\"\\nPrediction Table:\")\n",
        "print(data[[\"Emails\", \"TopicScore\", \"Attendance\", \"Predicted\", \"SHAP_Emails\", \"SHAP_Topic\", \"SHAP_Sum\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwvS0s_VvoCZ",
        "outputId": "96ee8e9e-337d-4eee-a52c-0932aa3d155b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Equation: y = 28.26 + 0.59*Emails + 14.30*TopicScore\n",
            "Baseline (mean attendance): 174.00\n",
            "\n",
            "Prediction Table:\n",
            "   Emails  TopicScore  Attendance   Predicted  SHAP_Emails  SHAP_Topic  \\\n",
            "0     100           8         200  201.594203     4.714976   22.879227   \n",
            "1      80           6         160  161.207729    -7.072464   -5.719807   \n",
            "2     120           9         230  227.681159    16.502415   37.178744   \n",
            "3      90           5         150  152.801932    -1.178744  -20.019324   \n",
            "4      70           4         130  126.714976   -12.966184  -34.318841   \n",
            "\n",
            "     SHAP_Sum  \n",
            "0  201.594203  \n",
            "1  161.207729  \n",
            "2  227.681159  \n",
            "3  152.801932  \n",
            "4  126.714976  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "uiWAex1wv2XU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_diabetes()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name=\"Disease_Progression\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "baseline = y_train.mean()\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "coef = model.coef_\n",
        "feature_means = X_train.mean()\n",
        "\n",
        "shap_values = pd.DataFrame((X_test - feature_means) * coef, columns=X_test.columns)\n",
        "\n",
        "shap_values[\"Baseline\"] = baseline\n",
        "shap_values[\"Prediction_from_SHAP\"] = shap_values.sum(axis=1)\n",
        "shap_values[\"Predicted\"] = y_pred\n",
        "shap_values[\"Actual\"] = y_test.values\n",
        "\n",
        "shap_values[\"Prediction_Comparison\"] = np.where(y_pred > y_test, \"Over Prediction\",\n",
        "                                               np.where(y_pred < y_test, \"Under Prediction\", \"Exact\"))\n",
        "\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "print(\"Coefficients:\", dict(zip(X.columns, coef)))\n",
        "print(\"Baseline:\", baseline)\n",
        "print(shap_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKkVHEmLv49_",
        "outputId": "466d6974-98a0-458c-d9a4-ad38b0bc1ec5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept: 151.34560453985995\n",
            "Coefficients: {'age': np.float64(37.904021350074984), 'sex': np.float64(-241.96436231273995), 'bmi': np.float64(542.4287585162899), 'bp': np.float64(347.70384391385636), 's1': np.float64(-931.4888458835163), 's2': np.float64(518.0622769833376), 's3': np.float64(163.41998299131035), 's4': np.float64(275.3179015786484), 's5': np.float64(736.1988589046839), 's6': np.float64(48.67065743196543)}\n",
            "Baseline: 153.73654390934846\n",
            "          age        sex        bmi         bp          s1         s2  \\\n",
            "287  1.663955  10.846180  -4.307759  -5.972983 -116.970979  65.277976   \n",
            "211  3.453897  10.846180  19.077692   7.195035   22.732658  -8.212397   \n",
            "72   2.352394 -12.218287  -3.138486  -4.775890  -96.464023  25.693757   \n",
            "321  3.591585  10.846180  27.262599  27.150567  -51.605057  19.366772   \n",
            "73   0.424765 -12.218287 -11.908030  -1.184613  -36.224840  27.964983   \n",
            "..        ...        ...        ...        ...         ...        ...   \n",
            "255  0.011702  10.846180 -36.462754  -2.381705    6.070756  -9.672471   \n",
            "90   0.424765  10.846180 -14.831212 -14.352631   27.859397 -22.975364   \n",
            "57  -1.089801  10.846180 -35.293481 -17.943908   82.971840 -53.636911   \n",
            "391 -0.952113  10.846180 -38.801299 -22.732278   54.774776 -25.733281   \n",
            "24  -2.466679  10.846180  18.493055  -8.367168   27.859397  -9.348010   \n",
            "\n",
            "            s3         s4         s5        s6    Baseline  \\\n",
            "287   3.297162   9.342171  22.981379 -0.346088  153.736544   \n",
            "211   0.288896 -10.976907 -17.471904 -1.152484  153.736544   \n",
            "72    9.313694  -0.817368  61.307307 -0.950885  153.736544   \n",
            "321 -12.345821  38.804835  71.729329  2.879497  153.736544   \n",
            "73   -0.914411   9.342171  -4.680936 -0.547687  153.736544   \n",
            "..         ...        ...        ...       ...         ...   \n",
            "255   6.907081 -10.976907  -3.325335  0.258709  153.736544   \n",
            "90   12.923613 -21.136446 -53.999312  0.460308  153.736544   \n",
            "57    8.712040 -21.136446 -42.235111 -3.370074  153.736544   \n",
            "391   3.297162 -10.976907 -66.515134 -2.563678  153.736544   \n",
            "24   -0.914411  -0.817368 -20.001912 -2.765277  153.736544   \n",
            "\n",
            "     Prediction_from_SHAP   Predicted  Actual Prediction_Comparison  \n",
            "287            139.547558  139.547558   219.0      Under Prediction  \n",
            "211            179.517208  179.517208    70.0       Over Prediction  \n",
            "72             134.038756  134.038756   202.0      Under Prediction  \n",
            "321            291.417029  291.417029   230.0       Over Prediction  \n",
            "73             123.789659  123.789659   111.0       Over Prediction  \n",
            "..                    ...         ...     ...                   ...  \n",
            "255            115.011800  115.011800   153.0      Under Prediction  \n",
            "90              78.955842   78.955842    98.0      Under Prediction  \n",
            "57              81.560873   81.560873    37.0       Over Prediction  \n",
            "391             54.379973   54.379973    63.0      Under Prediction  \n",
            "24             166.254352  166.254352   184.0      Under Prediction  \n",
            "\n",
            "[89 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question - 4"
      ],
      "metadata": {
        "id": "2V3IT84XNLqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shap\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    \"studytime\": [2, 3, 1, 4, 2, 3, 1, 4, 3, 2],\n",
        "    \"failures\": [0, 1, 0, 2, 1, 0, 3, 0, 1, 2],\n",
        "    \"health\": [5, 3, 4, 2, 4, 5, 3, 1, 4, 2],\n",
        "    \"absences\": [2, 10, 4, 6, 8, 3, 12, 1, 5, 7],\n",
        "    \"G3\": [15, 12, 14, 10, 11, 16, 8, 18, 13, 9]\n",
        "})\n",
        "\n",
        "features = data.drop(columns=[\"G3\"])\n",
        "target = data[\"G3\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "baseline = y_train.mean()\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "explainer = shap.Explainer(model, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "shap_df = pd.DataFrame(shap_values.values, columns=X_test.columns)\n",
        "shap_df[\"Baseline\"] = baseline\n",
        "shap_df[\"Prediction_from_SHAP\"] = shap_df.sum(axis=1) + baseline\n",
        "shap_df[\"Predicted\"] = y_pred\n",
        "shap_df[\"Actual\"] = y_test.values\n",
        "shap_df[\"Prediction_Comparison\"] = np.where(y_pred > y_test, \"Over Prediction\",\n",
        "                                            np.where(y_pred < y_test, \"Under Prediction\", \"Exact\"))\n",
        "\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "print(\"Coefficients:\", dict(zip(X_train.columns, model.coef_)))\n",
        "print(\"Baseline:\", baseline)\n",
        "print(shap_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM49Z3HONORZ",
        "outputId": "af7a6962-4731-4fbf-ccde-e92c614a1e36"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept: 17.537911869789596\n",
            "Coefficients: {'studytime': np.float64(0.043491685413083916), 'failures': np.float64(-2.555467337126729), 'health': np.float64(-0.6023113228353406), 'absences': np.float64(-0.1342243394645135)}\n",
            "Baseline: 12.142857142857142\n",
            "   studytime  failures    health  absences   Baseline  Prediction_from_SHAP  \\\n",
            "0   0.031065  0.365067 -0.602311  0.095875  12.142857             24.175410   \n",
            "1   0.031065  0.365067 -0.000000 -0.575247  12.142857             24.106599   \n",
            "2   0.031065  2.920534 -1.204623  0.364323  12.142857             26.397014   \n",
            "\n",
            "   Predicted  Actual Prediction_Comparison  \n",
            "0  12.032553      13      Under Prediction  \n",
            "1  11.963742      12      Under Prediction  \n",
            "2  14.254157      16      Under Prediction  \n"
          ]
        }
      ]
    }
  ]
}